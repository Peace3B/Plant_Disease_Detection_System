events {
    worker_connections 1024;
}

http {
    upstream api_backend {
        least_conn;  # Use least connections load balancing
        
        server api:8000 max_fails=3 fail_timeout=30s;
        # Add more API instances when scaling
        # server api_2:8000 max_fails=3 fail_timeout=30s;
        # server api_3:8000 max_fails=3 fail_timeout=30s;
    }

    server {
        listen 80;
        server_name localhost;

        # Increase timeouts for ML predictions
        proxy_connect_timeout 300s;
        proxy_send_timeout 300s;
        proxy_read_timeout 300s;

        # Increase body size for image uploads
        client_max_body_size 100M;

        location / {
            proxy_pass http://api_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # WebSocket support (if needed)
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
        }

        # Health check endpoint
        location /health {
            access_log off;
            proxy_pass http://api_backend;
        }

        # Status page for monitoring
        location /nginx_status {
            stub_status on;
            access_log off;
            allow 127.0.0.1;
            deny all;
        }
    }
}