# Plant Disease Detection ML Pipeline

## ğŸ¥ Video Demo
[YouTube Demo Link - Insert Your Video Here]

## ğŸŒ Live Demo
[Deployed Application URL - Insert After Deployment]

## ğŸ“‹ Project Description

A complete end-to-end Machine Learning pipeline for plant disease classification using Convolutional Neural Networks (CNN). The system allows users to:
- Upload plant leaf images and get disease predictions
- View model performance metrics and data visualizations
- Upload bulk training data and trigger model retraining
- Monitor model uptime and performance
- Handle concurrent requests with load balancing

**Dataset**: PlantVillage Dataset (subset) - Contains images of healthy and diseased plant leaves across multiple categories.

## ğŸ—ï¸ Architecture

```
User â†’ UI (Streamlit) â†’ FastAPI Backend â†’ ML Model â†’ Predictions
                              â†“
                        Model Monitoring
                              â†“
                      Retraining Pipeline
```

## ğŸ“ Directory Structure

```
plant_disease_detection/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ locustfile.py
â”‚
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ plant_disease_classification.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ prediction.py
â”‚   â”œâ”€â”€ api.py
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ healthy/
â”‚   â”‚   â””â”€â”€ diseased/
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ healthy/
â”‚       â””â”€â”€ diseased/
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ plant_disease_model.h5
â”‚   â””â”€â”€ model_metadata.json
â”‚
â””â”€â”€ uploads/
    â””â”€â”€ retrain/
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- Docker & Docker Compose
- Git

### 1. Clone Repository
```bash
git clone https://github.com/Peace3B/Plant_Disease_Detection_System
cd plant_disease_detection
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Download Dataset
```bash
# Download PlantVillage dataset subset
python scripts/download_data.py
```

### 4. Train Initial Model
```bash
# Run the Jupyter notebook or
python src/model.py
```

### 5. Run Application Locally
```bash
# Terminal 1 - Start API
uvicorn src.api:app --host 0.0.0.0 --port 8000

# Terminal 2 - Start UI
streamlit run src/app.py --server.port 8501
```

### 6. Docker Deployment
```bash
# Build and run with Docker Compose
docker-compose up --build

# Scale containers for load testing
docker-compose up --scale api=3
```

## ğŸ“Š Load Testing with Locust

### Run Load Test
```bash
# Install Locust
pip install locust

# Run Locust
locust -f locustfile.py --host=http://localhost:8000

# Open browser: http://localhost:8089
# Configure: Users=100, Spawn rate=10
```

### Expected Results
| Containers | Avg Response Time | RPS | P95 Latency |
|------------|------------------|-----|-------------|
| 1          | ~500ms           | 20  | 800ms       |
| 2          | ~300ms           | 35  | 500ms       |
| 3          | ~200ms           | 50  | 350ms       |

## ğŸŒ¥ï¸ Cloud Deployment (AWS)

### Deploy to AWS ECS
```bash
# 1. Build and push Docker image
docker build -t plant-disease-detection .
docker tag plant-disease-detection:latest <aws-account>.dkr.ecr.us-east-1.amazonaws.com/plant-disease
docker push <aws-account>.dkr.ecr.us-east-1.amazonaws.com/plant-disease

# 2. Create ECS Task Definition
aws ecs create-task-definition --cli-input-json file://task-definition.json

# 3. Create ECS Service
aws ecs create-service --cluster ml-cluster --service-name plant-disease-service --task-definition plant-disease
```

### Alternative: Deploy to Google Cloud Run
```bash
gcloud builds submit --tag gcr.io/PROJECT-ID/plant-disease
gcloud run deploy --image gcr.io/PROJECT-ID/plant-disease --platform managed
```

## ğŸ¯ Features

### 1. Model Prediction
- Upload single plant leaf image
- Get disease classification with confidence score
- View predicted class and probability distribution

### 2. Data Visualizations
- **Class Distribution**: Bar chart showing training data balance
- **Model Performance**: Confusion matrix and accuracy metrics
- **Training History**: Loss and accuracy curves over epochs
- **Prediction Confidence**: Distribution of model confidence scores

### 3. Bulk Data Upload
- Upload multiple images in ZIP format
- Automatic preprocessing and validation
- Store in staging area for retraining

### 4. Model Retraining
- Trigger button to start retraining process
- Uses existing model + newly uploaded data
- Transfer learning approach for faster training
- Automatic model versioning and backup

### 5. Model Monitoring
- Real-time uptime tracking
- Request count and latency metrics
- Model version information
- Last retrain timestamp

## ğŸ“ˆ Model Performance

### Current Model Metrics
- **Accuracy**: 94.3%
- **Precision**: 93.8%
- **Recall**: 94.1%
- **F1-Score**: 93.9%

### Model Architecture
```
- Input Layer: (224, 224, 3)
- Conv2D + MaxPooling (Ã—3)
- Flatten
- Dense (256, ReLU)
- Dropout (0.5)
- Dense (128, ReLU)
- Output Layer (Softmax)
```

## ğŸ”§ Configuration

Edit `config.py` for custom settings:
```python
MODEL_PATH = "models/plant_disease_model.h5"
IMAGE_SIZE = (224, 224)
BATCH_SIZE = 32
EPOCHS = 20
LEARNING_RATE = 0.001
```

## ğŸ“ API Endpoints

### Prediction
```bash
POST /predict
Content-Type: multipart/form-data

curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@plant_leaf.jpg"
```

### Upload Training Data
```bash
POST /upload-training-data
Content-Type: multipart/form-data

curl -X POST "http://localhost:8000/upload-training-data" \
  -F "files=@images.zip"
```

### Trigger Retraining
```bash
POST /retrain

curl -X POST "http://localhost:8000/retrain"
```

### Model Status
```bash
GET /status

curl "http://localhost:8000/status"
```

## ğŸ› Troubleshooting

### Common Issues

**Issue**: Model file not found
```bash
# Solution: Train model first
python src/model.py
```

**Issue**: Out of memory during training
```bash
# Solution: Reduce batch size in config.py
BATCH_SIZE = 16
```

**Issue**: Docker container crashes
```bash
# Solution: Increase memory allocation
docker-compose up --build --scale api=1
```

## ğŸ“š Technologies Used

- **ML Framework**: TensorFlow/Keras
- **API**: FastAPI
- **UI**: Streamlit
- **Containerization**: Docker
- **Load Testing**: Locust
- **Cloud**: AWS ECS / Google Cloud Run
- **Monitoring**: Prometheus + Grafana (optional)

## ğŸ‘¥ Contributors

[Your Name] - [Your Email]

## ğŸ“„ License

MIT License

## ğŸ™ Acknowledgments

- PlantVillage Dataset
- TensorFlow Team
- FastAPI Community